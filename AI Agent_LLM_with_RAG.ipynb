{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sample code to use LLM and RAG to read a Document (PDF, Excel, Word, CSV, HTML) and provide inputs from it"
      ],
      "metadata": {
        "id": "X9fCxSTJCvc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai faiss-cpu python-dotenv"
      ],
      "metadata": {
        "id": "GCl2IVV9-0yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP & ENVIRONMENT"
      ],
      "metadata": {
        "id": "pG1jAoqJDDzo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6QQ3XZwi-iR7"
      },
      "outputs": [],
      "source": [
        "#  Import necessary libraries\n",
        "import os\n",
        "from dotenv import load_dotenv  # For loading your OpenAI key securely\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Read PDF"
      ],
      "metadata": {
        "id": "7QYggjLMDcot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Provide the path to your PDF document. Here I have uploaded SCB annual report ( PDF) is Google Drive and shared the path\n",
        "pdf_path = \"/content/drive/MyDrive/GLEAN POC DATA/SCB 2023 Annual Report/standard-chartered-plc-full-year-2023-report.pdf\"\n",
        "\n",
        "# Load the PDF using PyPDFLoader. If you are using other file type then refer the code snippets below.\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "# We have PyPDFLoader as we have used a simple PDF as input in the code example. For PDF which has many tables its recommended to use PDFPlumberLoader instead. For PDF with scanned images to be extracted you can use UnstructuredPDFLoader.\n"
      ],
      "metadata": {
        "id": "gs74waOj_L1b"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##If using DOC/DOCX (Word) use UnstructuredWordDocumentLoader or Docx2txtLoader to extract content\n",
        "#\n",
        "#from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
        "#loader = UnstructuredWordDocumentLoader(\"file.docx\")\n",
        "#documents = loader.load()\n",
        "#\n",
        "##If using XLS/XLSX (Excel) use PandasExcelLoader or UnstructuredExcelLoader  to extract content\n",
        "#\n",
        "#from langchain.document_loaders import UnstructuredExcelLoader\n",
        "#loader = UnstructuredExcelLoader(\"file.xlsx\")\n",
        "#documents = loader.load()\n",
        "#\n",
        "##If using HTML use UnstructuredHTMLLoader to extract content\n",
        "#\n",
        "#from langchain.document_loaders import UnstructuredHTMLLoader\n",
        "#loader = UnstructuredHTMLLoader(\"file.html\")\n",
        "#documents = loader.load()\n",
        "#\n",
        "##If using CSV use CSVLoader or PandasCSVLoader to extract content\n",
        "#from langchain.document_loaders import UnstructuredHTMLLoader\n",
        "#loader = UnstructuredHTMLLoader(\"file.html\")\n",
        "#documents = loader.load()\n",
        "#\n",
        "##If using JSON use JSONLoader to extract content\n",
        "#from langchain.document_loaders import JSONLoader\n",
        "#loader = JSONLoader(\n",
        "#    file_path=\"file.json\",\n",
        "#    jq_schema=\".records[].summary\",\n",
        "#    text_content=True\n",
        "#)\n",
        "#documents = loader.load()\n",
        "#\n",
        "##If using Website use the below code to extract content\n",
        "#\n",
        "#from langchain.document_loaders import WebBaseLoader\n",
        "#loader = WebBaseLoader(\"https://example.com\")\n",
        "#documents = loader.load()"
      ],
      "metadata": {
        "id": "VEdFhxltB3fO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your OpenAI API key from a .env file\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "g26NuEsG_Kod"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunk the Text"
      ],
      "metadata": {
        "id": "p3S-OeDEDehq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split large documents into small readable chunks\n",
        "# Useful for the LLM to process smaller bites of data\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,       # Number of characters per chunk\n",
        "    chunk_overlap=100     # Overlap helps maintain context across chunks\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "print(f\"âœ… Number of chunks created: {len(chunks)}\")\n",
        "print(f\"ðŸ“„ First chunk preview:\\n{chunks[0].page_content}\")\n",
        "\n",
        "# We have used RecursiveCharacterTextSplitter in this example. Howeever there are alternate chunking splitters based on user requirements that you can leverage\n",
        "#| Splitter Class                          | Description                                           | Use Case                                           |\n",
        "#| --------------------------------------- | ----------------------------------------------------- | -------------------------------------------------- |\n",
        "#| `RecursiveCharacterTextSplitter`        | Splits at paragraphs â†’ sentences â†’ words â†’ characters | Best for generic documents (PDFs, policies, books) |\n",
        "#| `CharacterTextSplitter`                 | Splits at fixed character limits (naive)              | Simple logs, structured text                       |\n",
        "#| `TokenTextSplitter`                     | Splits by token count (uses tokenizer like tiktoken)  | Precise control for GPT-3.5/4                      |\n",
        "#| `SentenceTransformersTokenTextSplitter` | Aware of sentence boundaries + tokens                 | Best for multilingual and NLP-heavy documents      |\n",
        "#| `MarkdownHeaderTextSplitter`            | Splits based on Markdown headers                      | Technical docs, blog posts, notebooks              |\n",
        "#| `HTMLHeaderTextSplitter`                | Splits based on HTML tags                             | Websites, web-scraped data                         |\n",
        "#| `Language` Splitters                    | Code-aware (Python, JS, etc.)                         | Splits by function/class â€” great for code docs     |"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV3jQIk1ACjK",
        "outputId": "e3a94886-777d-42c5-fba4-340d1aa3d880"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Number of chunks created: 5004\n",
            "ðŸ“„ First chunk preview:\n",
            "Annual Report 2023\n",
            "[[Connecting \n",
            "the worldâ€™s \n",
            "most dynamic \n",
            "markets]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Embeddings (Convert Text to Math)"
      ],
      "metadata": {
        "id": "I7UCYp8hDs8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text chunks into numerical vectors\n",
        "# These embeddings help match relevant chunks to your question\n",
        "embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n"
      ],
      "metadata": {
        "id": "JGpClTg4AFQt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Vector Store"
      ],
      "metadata": {
        "id": "WNRSWUjIDyJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the vectorized chunks in FAISS (in-memory vector database)\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "# We have used FAISS opens ource vector DB here. There are alternate solutions you can try like Chroma, Weaviate, Qdrant, Milvus"
      ],
      "metadata": {
        "id": "-9c2hzs2BFYc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the LLM"
      ],
      "metadata": {
        "id": "Z2lI3ypWD2qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI LLM (GPT-4 Turbo) with low temperature for accurate answers. Provide the LLM of your choise here\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    temperature=0.3,\n",
        "    api_key=openai_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "4YGxk3wjBLfP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup RetrievalQA Chain"
      ],
      "metadata": {
        "id": "s8oXSa-LECsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect the retriever (search engine) and the LLM\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# Create a Retrieval-Augmented Generation (RAG) chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "hq--fp79BNgP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask Questions!"
      ],
      "metadata": {
        "id": "BVKQJ_TBEIn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§ª Ask questions to your agent\n",
        "def ask_rag_agent(query: str):\n",
        "    print(f\"\\nðŸ§‘â€ðŸŽ“ User Query: {query}\")\n",
        "    result = rag_chain.invoke({\"query\": query})\n",
        "\n",
        "    print(\"\\nâœ… Answer:\")\n",
        "    print(result[\"result\"])\n",
        "\n",
        "    print(\"\\nðŸ“š Retrieved Contexts:\")\n",
        "    for doc in result[\"source_documents\"]:\n",
        "        print(\"-->\", doc.page_content.strip()[:200], \"...\")\n"
      ],
      "metadata": {
        "id": "MrvOxPMYBR7Q"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: Ask a question\n",
        "ask_rag_agent(\"What was the profit for SCB in 2023?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojMZOmrVBTDI",
        "outputId": "6bd5cc02-0528-48dc-8399-6852c46f4f93"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§‘â€ðŸŽ“ User Query: What was the profit for SCB in 2023?\n",
            "\n",
            "âœ… Answer:\n",
            "The profit before taxation for Standard Chartered Bank (SCB) in 2023 was $5,093 million.\n",
            "\n",
            "ðŸ“š Retrieved Contexts:\n",
            "--> revenue growth in 2023.\n",
            "Additionally, we made significant progress in our advisory \n",
            "business with the launch of SC Wealth Select in 14 markets. \n",
            "SCÂ Wealth Select aims to bring a portfolio approach to  ...\n",
            "--> SCB 2021 baseline\n",
            "7. 3%\n",
            "11.8%\n",
            "2021\n",
            "30%\n",
            "20%\n",
            "25%\n",
            "15%\n",
            "5%\n",
            "0%\n",
            "-5%\n",
            "-10%\n",
            "-20%\n",
            "-25%\n",
            "Alignment delta (against IMO trajectory %)\n",
            "22 23 24 25 26 27 28 29 2030 Year\n",
            "-11.8%\n",
            "Progress in the year\n",
            "In 2022, the Group  ...\n",
            "--> 490\n",
            "Standard Chartered â€“ Annual Report 2023\n",
            "Supplementary information Supplementary financial information\n",
            "Five-year summary\n",
            "2023 \n",
            "$million\n",
            "2022 \n",
            "$million\n",
            "2021 \n",
            "$million\n",
            "2020 \n",
            "$million\n",
            "2019\n",
            "$million\n",
            "Op ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Happy Learning"
      ],
      "metadata": {
        "id": "DOvIy3FxHIc3"
      }
    }
  ]
}